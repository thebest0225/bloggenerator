import urllib.request
import urllib.parse
import json
import os
import time
import re
from collections import Counter
from openai import OpenAI
import prompts

def load_env_variables():
    """
    .env íŒŒì¼ì—ì„œ ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ ì •ë³´ì™€ OpenAI API í‚¤ë¥¼ ì½ì–´ì˜µë‹ˆë‹¤.
    """
    env_vars = {}
    try:
        with open('.env', 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    except FileNotFoundError:
        print("Error: .env íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ .env íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”:")
        print("NAVER_CLIENT_ID=your_naver_client_id")
        print("NAVER_CLIENT_SECRET_KEY=your_naver_client_secret")
        print("OPENAI_API_KEY=your_openai_api_key")
        return None, None, None
    
    client_id = env_vars.get('NAVER_CLIENT_ID')
    client_secret = env_vars.get('NAVER_CLIENT_SECRET_KEY')
    openai_api_key = env_vars.get('OPENAI_API_KEY')
    
    if not client_id or not client_secret:
        print("Error: .env íŒŒì¼ì—ì„œ ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
    
    if not openai_api_key:
        print("Error: .env íŒŒì¼ì—ì„œ OPENAI_API_KEYë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. GPT ë¶„ì„ ê¸°ëŠ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return None, None, None
    
    return client_id, client_secret, openai_api_key

def search_naver_blog(query, client_id, client_secret, display=50, sort='date'):
    """
    ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ APIë¥¼ í˜¸ì¶œí•˜ì—¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    enc_text = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/blog.json?query={enc_text}&display={display}&sort={sort}"
    
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        response = urllib.request.urlopen(request)
        rescode = response.getcode()
        
        if rescode == 200:
            response_body = response.read()
            return json.loads(response_body.decode('utf-8'))
        else:
            print(f"Error Code: {rescode}")
            return None
            
    except Exception as e:
        print(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def clean_html_tags(text):
    """
    HTML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  íŠ¹ìˆ˜ë¬¸ìë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    """
    text = text.replace('<b>', '').replace('</b>', '')
    text = text.replace('&quot;', '"').replace('&lt;', '<').replace('&gt;', '>')
    text = text.replace('&amp;', '&').replace('&#39;', "'")
    return text.strip()

def extract_blog_data(search_result):
    """
    ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¸”ë¡œê·¸ ì œëª©ê³¼ ì„¤ëª…ì„ ì¶”ì¶œí•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not search_result or 'items' not in search_result:
        return [], []
    
    titles = []
    descriptions = []
    
    for item in search_result['items']:
        clean_title = clean_html_tags(item['title'])
        clean_desc = clean_html_tags(item['description'])
        titles.append(clean_title)
        descriptions.append(clean_desc)
    
    return titles, descriptions

def analyze_title_patterns(titles):
    """
    ì œëª©ë“¤ì˜ ê¸°ë³¸ì ì¸ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    """
    analysis = {
        'total_count': len(titles),
        'avg_length': sum(len(title) for title in titles) / len(titles) if titles else 0,
        'length_distribution': {},
        'has_numbers': 0,
        'has_question_mark': 0,
        'has_exclamation': 0,
        'has_parentheses': 0,
        'has_quotes': 0,
        'keyword_frequency': Counter()
    }
    
    # ê¸¸ì´ë³„ ë¶„í¬
    for title in titles:
        length_range = f"{(len(title)//10)*10}-{(len(title)//10)*10+9}"
        analysis['length_distribution'][length_range] = analysis['length_distribution'].get(length_range, 0) + 1
    
    # íŒ¨í„´ ë¶„ì„
    for title in titles:
        if re.search(r'\d', title):
            analysis['has_numbers'] += 1
        if '?' in title:
            analysis['has_question_mark'] += 1
        if '!' in title:
            analysis['has_exclamation'] += 1
        if '(' in title or ')' in title:
            analysis['has_parentheses'] += 1
        if '"' in title or "'" in title:
            analysis['has_quotes'] += 1
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        words = re.findall(r'[ê°€-í£]{2,}', title)
        analysis['keyword_frequency'].update(words)
    
    return analysis





def analyze_with_gpt(titles, descriptions, query, openai_api_key, analysis_type='comprehensive'):
    """
    GPT-4oë¥¼ ì‚¬ìš©í•˜ì—¬ ë¸”ë¡œê·¸ ì œëª©ë“¤ì„ ì‹¬í™” ë¶„ì„í•©ë‹ˆë‹¤.
    """
    if not openai_api_key:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    if not titles:
        return "ë¶„ì„í•  ë¸”ë¡œê·¸ ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        client = OpenAI(api_key=openai_api_key)
        
        # ê¸°ë³¸ íŒ¨í„´ ë¶„ì„
        basic_analysis = analyze_title_patterns(titles)
        
        # prompts.pyì—ì„œ ë¶„ì„ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        prompt = prompts.get_analysis_prompt(analysis_type, query, titles, descriptions, basic_analysis)
        
        print("GPT-4oë¡œ ë¸”ë¡œê·¸ ì œëª© ì‹¬í™” ë¶„ì„ ì¤‘...")
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system", 
                    "content": prompts.get_system_prompt_analysis()
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def generate_new_titles(analysis_result, query, openai_api_key, num_titles=10):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ì œëª©ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if not openai_api_key:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        client = OpenAI(api_key=openai_api_key)
        
        # prompts.pyì—ì„œ ì œëª© ìƒì„± í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        prompt = prompts.create_title_generation_prompt(query, analysis_result, num_titles)
        
        print(f"GPT-4oë¡œ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ì œëª© {num_titles}ê°œ ìƒì„± ì¤‘...")
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "system", 
                    "content": prompts.get_system_prompt_generation()
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            temperature=0.8,
            max_tokens=3000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"ì œëª© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def display_blog_titles(search_result):
    """
    ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ë¸”ë¡œê·¸ ì œëª©ë“¤ì„ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    if not search_result or 'items' not in search_result:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    items = search_result['items']
    total = search_result.get('total', 0)
    
    print(f"\n=== ê²€ìƒ‰ ê²°ê³¼ ì´ {total}ê°œ ì¤‘ ìƒìœ„ {len(items)}ê°œ ===\n")
    
    for i, item in enumerate(items, 1):
        title = clean_html_tags(item['title'])
        print(f"{i:2d}. {title}")
    
    print()

def get_number_input(prompt, min_val=1, max_val=50, default=10):
    """
    ìˆ«ì ì…ë ¥ì„ ë°›ê³  ìœ íš¨ì„±ì„ ê²€ì‚¬í•©ë‹ˆë‹¤.
    """
    while True:
        user_input = input(f"{prompt} ({min_val}-{max_val}, ê¸°ë³¸ê°’: {default}): ").strip()
        
        if not user_input:
            return default
        
        try:
            num = int(user_input)
            if min_val <= num <= max_val:
                return num
            else:
                print(f"âŒ {min_val}ê³¼ {max_val} ì‚¬ì´ì˜ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        except ValueError:
            print("âŒ ì˜¬ë°”ë¥¸ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

def save_results_to_file(query, analysis_result, generated_titles):
    """
    ë¶„ì„ ê²°ê³¼ì™€ ìƒì„±ëœ ì œëª©ë“¤ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    filename = f"blog_analysis_{query}_{timestamp}.txt"
    
    try:
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(f"=== ë¸”ë¡œê·¸ ì œëª© ë¶„ì„ ë° ìƒì„± ê²°ê³¼ ===\n")
            f.write(f"ê²€ìƒ‰ í‚¤ì›Œë“œ: {query}\n")
            f.write(f"ë¶„ì„ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("=== ì‹¬í™” ë¶„ì„ ê²°ê³¼ ===\n")
            f.write(analysis_result)
            f.write("\n\n")
            
            f.write("=== ìƒì„±ëœ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ì œëª©ë“¤ ===\n")
            f.write(generated_titles)
            f.write("\n")
        
        print(f"\nğŸ’¾ ê²°ê³¼ê°€ '{filename}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        print(f"âŒ íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    """
    ë©”ì¸ í•¨ìˆ˜: ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰, ì‹¬í™” ë¶„ì„, ìƒˆ ì œëª© ìƒì„±ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """
    print("="*60)
    print("ğŸš€ ê³ ë„í™”ëœ ë¸”ë¡œê·¸ ì œëª© ë¶„ì„ ë° ìƒì„± í”„ë¡œê·¸ë¨")
    print("="*60)
    
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    client_id, client_secret, openai_api_key = load_env_variables()
    if not client_id or not client_secret or not openai_api_key:
        return
    
    print(f"âœ… ë„¤ì´ë²„ í´ë¼ì´ì–¸íŠ¸ ID: {client_id}")
    print(f"âœ… OpenAI API í‚¤: {openai_api_key[:8]}...")
    print()
    
    while True:
        # ê²€ìƒ‰ í‚¤ì›Œë“œ ì…ë ¥
        query = input("ğŸ” ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œ: 'quit' ë˜ëŠ” 'exit'): ").strip()
        
        if query.lower() in ['quit', 'exit', 'ì¢…ë£Œ']:
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        
        if not query:
            print("âŒ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        # ê²€ìƒ‰ ê°œìˆ˜ ì„¤ì •
        search_count = get_number_input("ğŸ“Š ë¶„ì„í•  ë¸”ë¡œê·¸ ê°œìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”", 10, 100, 50)
        
        # ì •ë ¬ ë°©ì‹ ì„ íƒ
        print("\nğŸ“ˆ ì •ë ¬ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. ë‚ ì§œìˆœ (ìµœì‹ ìˆœ)")
        print("2. ì •í™•ë„ìˆœ")
        
        sort_choice = input("ì„ íƒ (1 ë˜ëŠ” 2, ê¸°ë³¸ê°’: 1): ").strip()
        sort_method = 'date' if sort_choice != '2' else 'sim'
        sort_name = 'ë‚ ì§œìˆœ' if sort_method == 'date' else 'ì •í™•ë„ìˆœ'
        
        print(f"\nğŸ” '{query}' ê²€ìƒ‰ ì¤‘... ({sort_name}, {search_count}ê°œ)")
        
        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì‹¤í–‰
        result = search_naver_blog(query, client_id, client_secret, display=search_count, sort=sort_method)
        
        if result:
            display_blog_titles(result)
            
            # ë¸”ë¡œê·¸ ë°ì´í„° ì¶”ì¶œ
            titles, descriptions = extract_blog_data(result)
            
            print("\n" + "="*60)
            print("ğŸ§  ì‹¬í™” ë¶„ì„ ì‹œì‘")
            print("="*60)
            
            # GPT ì‹¬í™” ë¶„ì„ ì‹¤í–‰
            analysis_result = analyze_with_gpt(titles, descriptions, query, openai_api_key)
            
            print("\n" + "="*60)
            print("ğŸ“‹ ë¸”ë¡œê·¸ ì œëª© ì‹¬í™” ë¶„ì„ ê²°ê³¼")
            print("="*60)
            print(analysis_result)
            
            # ìƒˆë¡œìš´ ì œëª© ìƒì„± ì˜µì…˜
            print("\n" + "="*60)
            print("âœ¨ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ì œëª© ìƒì„±")
            print("="*60)
            
            generate_choice = input("ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì œëª©ì„ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’: y): ").strip().lower()
            
            if generate_choice != 'n':
                # ìƒì„±í•  ì œëª© ê°œìˆ˜ ì…ë ¥
                num_titles = get_number_input("ğŸ’¡ ìƒì„±í•  ì œëª© ê°œìˆ˜ë¥¼ ì„¤ì •í•˜ì„¸ìš”", 5, 30, 10)
                
                # ìƒˆë¡œìš´ ì œëª© ìƒì„±
                generated_titles = generate_new_titles(analysis_result, query, openai_api_key, num_titles)
                
                print("\n" + "="*60)
                print(f"ğŸ¯ ìƒˆë¡­ê²Œ ìƒì„±ëœ ë¸”ë¡œê·¸ ì œëª© {num_titles}ê°œ")
                print("="*60)
                print(generated_titles)
                
                # ê²°ê³¼ ì €ì¥ ì˜µì…˜
                save_choice = input("\nğŸ’¾ ë¶„ì„ ê²°ê³¼ì™€ ìƒì„±ëœ ì œëª©ì„ íŒŒì¼ë¡œ ì €ì¥í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’: y): ").strip().lower()
                
                if save_choice != 'n':
                    save_results_to_file(query, analysis_result, generated_titles)
            
        else:
            print("âŒ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        print("\n" + "="*80)
        print()

if __name__ == "__main__":
    main() 