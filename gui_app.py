import streamlit as st
import urllib.request
import urllib.parse
import urllib.error
import json
import re
import time
from collections import Counter
from openai import OpenAI
import prompts
import io
import requests

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="KeiaiLAB ë¸”ë¡œê·¸ ê¸€ìƒì„±ê¸°",
    page_icon="âœ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-size: 3rem;
        font-weight: 800;
        margin-bottom: 0.5rem;
    }
    
    .sub-header {
        text-align: center;
        color: #666;
        font-size: 1.2rem;
        margin-bottom: 2rem;
    }
    
    .metric-container {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        margin: 0.5rem 0;
    }
    
    .result-container {
        background: #f8f9fa;
        padding: 1.5rem;
        border-radius: 15px;
        border-left: 5px solid #667eea;
        margin: 1rem 0;
    }
    
    .generated-title {
        background: white;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
        border-left: 4px solid #764ba2;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    
    .stButton>button {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        border: none;
        border-radius: 25px;
        padding: 0.5rem 2rem;
        font-weight: 600;
        transition: all 0.3s ease;
    }
    
    .stButton>button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.2);
    }
    
    .sidebar-content {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def load_env_variables():
    """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
    env_vars = {}
    try:
        with open('.env', 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    except FileNotFoundError:
        return None, None, None
    
    return (
        env_vars.get('NAVER_CLIENT_ID'),
        env_vars.get('NAVER_CLIENT_SECRET_KEY'),
        env_vars.get('OPENAI_API_KEY')
    )

def test_naver_api_connection(client_id, client_secret):
    """ë„¤ì´ë²„ API ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸"""
    try:
        headers = {
            'X-Naver-Client-Id': client_id,
            'X-Naver-Client-Secret': client_secret
        }
        # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ API ì—°ê²° í™•ì¸
        url = "https://openapi.naver.com/v1/search/blog"
        params = {'query': 'test', 'display': 1}
        
        response = requests.get(url, headers=headers, params=params, timeout=5)
        return response.status_code == 200
    except:
        return False

def test_openai_api_connection(api_key):
    """OpenAI API ì—°ê²° ìƒíƒœ í…ŒìŠ¤íŠ¸"""
    try:
        client = OpenAI(api_key=api_key)
        # ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ ì—°ê²° í™•ì¸
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": "í…ŒìŠ¤íŠ¸"}],
            max_tokens=1,
            timeout=5
        )
        return True
    except:
        return False

def search_naver_blog(query, client_id, client_secret, display=50, sort='date'):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰"""
    enc_text = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/blog.json?query={enc_text}&display={display}&sort={sort}"
    
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            response_body = response.read()
            return json.loads(response_body.decode('utf-8'))
        else:
            st.error(f"API ì‘ë‹µ ì˜¤ë¥˜: HTTP {response.getcode()}")
            return None
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8')
        st.error(f"ë„¤ì´ë²„ API ì˜¤ë¥˜ ({e.code}): {error_body}")
        st.info("ğŸ’¡ .env íŒŒì¼ì˜ NAVER_CLIENT_SECRET_KEYë¥¼ ë„¤ì´ë²„ ê°œë°œìì„¼í„°ì—ì„œ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def clean_html_tags(text):
    """HTML íƒœê·¸ ì œê±°"""
    text = text.replace('<b>', '').replace('</b>', '')
    text = text.replace('&quot;', '"').replace('&lt;', '<').replace('&gt;', '>')
    text = text.replace('&amp;', '&').replace('&#39;', "'")
    return text.strip()

def extract_blog_data(search_result):
    """ë¸”ë¡œê·¸ ë°ì´í„° ì¶”ì¶œ"""
    if not search_result or 'items' not in search_result:
        return [], []
    
    titles = []
    descriptions = []
    
    for item in search_result['items']:
        clean_title = clean_html_tags(item['title'])
        clean_desc = clean_html_tags(item['description'])
        titles.append(clean_title)
        descriptions.append(clean_desc)
    
    return titles, descriptions

def analyze_title_patterns(titles):
    """ì œëª© íŒ¨í„´ ë¶„ì„"""
    analysis = {
        'total_count': len(titles),
        'avg_length': sum(len(title) for title in titles) / len(titles) if titles else 0,
        'length_distribution': {},
        'has_numbers': 0,
        'has_question_mark': 0,
        'has_exclamation': 0,
        'has_parentheses': 0,
        'has_quotes': 0,
        'keyword_frequency': Counter()
    }
    
    for title in titles:
        length_range = f"{(len(title)//10)*10}-{(len(title)//10)*10+9}"
        analysis['length_distribution'][length_range] = analysis['length_distribution'].get(length_range, 0) + 1
        
        if re.search(r'\d', title):
            analysis['has_numbers'] += 1
        if '?' in title:
            analysis['has_question_mark'] += 1
        if '!' in title:
            analysis['has_exclamation'] += 1
        if '(' in title or ')' in title:
            analysis['has_parentheses'] += 1
        if '"' in title or "'" in title:
            analysis['has_quotes'] += 1
        
        words = re.findall(r'[ê°€-í£]{2,}', title)
        analysis['keyword_frequency'].update(words)
    
    return analysis

def analyze_with_gpt(titles, descriptions, query, openai_api_key, analysis_type='comprehensive'):
    """GPT ë¶„ì„"""
    if not openai_api_key:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    if not titles:
        return "ë¶„ì„í•  ë¸”ë¡œê·¸ ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤."
    
    try:
        client = OpenAI(api_key=openai_api_key)
        basic_analysis = analyze_title_patterns(titles)
        prompt = prompts.get_analysis_prompt(analysis_type, query, titles, descriptions, basic_analysis)
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompts.get_system_prompt_analysis()},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=4000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def generate_new_titles(analysis_result, query, openai_api_key, num_titles=10):
    """ìƒˆë¡œìš´ ì œëª© ìƒì„±"""
    if not openai_api_key:
        return "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        client = OpenAI(api_key=openai_api_key)
        prompt = prompts.create_title_generation_prompt(query, analysis_result, num_titles)
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompts.get_system_prompt_generation()},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8,
            max_tokens=3000
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        return f"ì œëª© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

def main():
    # í—¤ë”
    st.markdown('<h1 class="main-header">âœ¨ KeiaiLAB ë¸”ë¡œê·¸ ê¸€ìƒì„±ê¸°</h1>', unsafe_allow_html=True)
    st.markdown('<p class="sub-header">AI ê¸°ë°˜ ë¸”ë¡œê·¸ ì œëª© ë¶„ì„ ë° ìƒì„± ë„êµ¬</p>', unsafe_allow_html=True)
    
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    client_id, client_secret, openai_api_key = load_env_variables()
    
    if not all([client_id, client_secret, openai_api_key]):
        st.error("ğŸš¨ .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”. API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.info("""
        ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ .env íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
        ```
        NAVER_CLIENT_ID=your_naver_client_id
        NAVER_CLIENT_SECRET_KEY=your_naver_client_secret
        OPENAI_API_KEY=your_openai_api_key
        ```
        """)
        return
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.markdown("### âš™ï¸ ì„¤ì •")
        
        # API í‚¤ ìƒíƒœ í‘œì‹œ
        with st.spinner("API ì—°ê²° ìƒíƒœ í™•ì¸ ì¤‘..."):
            naver_status = test_naver_api_connection(client_id, client_secret)
            openai_status = test_openai_api_connection(openai_api_key)
        
        if naver_status:
            st.success("âœ… ë„¤ì´ë²„ API ì—°ê²°ë¨")
        else:
            st.warning("âš ï¸ ë„¤ì´ë²„ API ì—°ê²° í™•ì¸ í•„ìš”")
            
        if openai_status:
            st.success("âœ… OpenAI API ì—°ê²°ë¨")
        else:
            st.warning("âš ï¸ OpenAI API ì—°ê²° í™•ì¸ í•„ìš”")
        
        st.markdown("---")
        
        # ê²€ìƒ‰ ì„¤ì •
        st.markdown("### ğŸ” ê²€ìƒ‰ ì„¤ì •")
        search_count = st.slider("ë¶„ì„í•  ë¸”ë¡œê·¸ ê°œìˆ˜", 10, 100, 50)
        sort_method = st.radio("ì •ë ¬ ë°©ì‹", ["ë‚ ì§œìˆœ (ìµœì‹ ìˆœ)", "ì •í™•ë„ìˆœ"])
        sort_value = 'date' if sort_method == "ë‚ ì§œìˆœ (ìµœì‹ ìˆœ)" else 'sim'
        
        st.markdown("---")
        
        # ë¶„ì„ ì„¤ì •
        st.markdown("### ğŸ§  ë¶„ì„ ì„¤ì •")
        analysis_types = prompts.get_available_analysis_types()
        analysis_labels = [f"{config['name']} - {config['description']}" for config in analysis_types.values()]
        analysis_keys = list(analysis_types.keys())
        
        selected_analysis = st.selectbox(
            "ë¶„ì„ ìœ í˜• ì„ íƒ",
            options=analysis_keys,
            format_func=lambda x: analysis_types[x]['name'],
            help="ì›í•˜ëŠ” ë¶„ì„ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        st.markdown("---")
        
        # ì œëª© ìƒì„± ì„¤ì •
        st.markdown("### âœ¨ ì œëª© ìƒì„± ì„¤ì •")
        num_titles = st.slider("ìƒì„±í•  ì œëª© ê°œìˆ˜", 5, 30, 10)
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.markdown("### ğŸ¯ í‚¤ì›Œë“œ ì…ë ¥")
        query = st.text_input(
            "ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ë°˜ë ¤ë™ë¬¼, ìš”ë¦¬, ì—¬í–‰ ë“±",
            help="ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
    
    with col2:
        st.markdown("### ğŸš€ ì‹¤í–‰")
        # ë¶„ì„ ì‹¤í–‰
        if st.button("ë¶„ì„ ì‹œì‘", key="main_analysis_button", use_container_width=True):
            if not query.strip():
                st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")
                return
            
            # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
            if 'analysis_result' in st.session_state:
                del st.session_state.analysis_result
            if 'titles' in st.session_state:
                del st.session_state.titles
            
            with st.spinner("ğŸ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì¤‘..."):
                search_result = search_naver_blog(query, client_id, client_secret, search_count, sort_value)
            
            if search_result:
                titles, descriptions = extract_blog_data(search_result)
                
                if titles:
                    # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
                    st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ì´ ê²€ìƒ‰ ê²°ê³¼", f"{search_result.get('total', 0):,}ê°œ")
                    with col2:
                        st.metric("ìˆ˜ì§‘ëœ ì œëª©", f"{len(titles)}ê°œ")
                    with col3:
                        st.metric("í‰ê·  ì œëª© ê¸¸ì´", f"{sum(len(t) for t in titles)/len(titles):.1f}ì")
                    
                    # ë¶„ì„ ì‹¤í–‰
                    with st.spinner("ğŸ§  AI ë¶„ì„ ì¤‘..."):
                        analysis_result = analyze_with_gpt(titles, descriptions, query, openai_api_key, selected_analysis)
                    
                    st.session_state.analysis_result = analysis_result
                    st.session_state.titles = titles
                    st.session_state.query = query
                    
                    # íƒ­ìœ¼ë¡œ ê²°ê³¼ ë¶„ë¦¬
                    tab1, tab2 = st.tabs(["ğŸ“ ìˆ˜ì§‘ëœ ì œëª© ëª©ë¡", "ğŸ“‹ AI ë¶„ì„ ê²°ê³¼"])
                    
                    with tab1:
                        st.markdown("#### ğŸ” ê²€ìƒ‰ëœ ë¸”ë¡œê·¸ ì œëª©ë“¤")
                        for i, title in enumerate(titles, 1):
                            st.write(f"**{i:2d}.** {title}")
                    
                    with tab2:
                        st.markdown("#### ğŸ§  AI ë¶„ì„ ë³´ê³ ì„œ")
                        st.markdown(f'<div class="result-container">{analysis_result}</div>', unsafe_allow_html=True)
                    
                    # ì œëª© ìƒì„± ì˜µì…˜
                    st.markdown("### âœ¨ ìƒˆë¡œìš´ ì œëª© ìƒì„±")
                    
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        if st.button("ğŸ¯ ìƒˆë¡œìš´ ì œëª© ìƒì„±", key="generate_titles_button", use_container_width=True):
                            with st.spinner(f"âœ¨ {num_titles}ê°œì˜ ìƒˆë¡œìš´ ì œëª© ìƒì„± ì¤‘..."):
                                generated_titles = generate_new_titles(analysis_result, query, openai_api_key, num_titles)
                            
                            st.session_state.generated_titles = generated_titles
                            
                            # ìƒì„±ëœ ì œëª© í‘œì‹œ
                            st.markdown("### ğŸ‰ ìƒì„±ëœ ìƒˆë¡œìš´ ì œëª©ë“¤")
                            st.markdown(f'<div class="result-container">{generated_titles}</div>', unsafe_allow_html=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", key="download_results_button", use_container_width=True):
                            if 'analysis_result' in st.session_state:
                                # ê²°ê³¼ íŒŒì¼ ìƒì„±
                                timestamp = time.strftime("%Y%m%d_%H%M%S")
                                filename = f"blog_analysis_{query}_{timestamp}.txt"
                                
                                content = f"""=== KeiaiLAB ë¸”ë¡œê·¸ ì œëª© ë¶„ì„ ë° ìƒì„± ê²°ê³¼ ===
ê²€ìƒ‰ í‚¤ì›Œë“œ: {query}
ë¶„ì„ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}
ë¶„ì„ ìœ í˜•: {analysis_types[selected_analysis]['name']}

=== ì‹¬í™” ë¶„ì„ ê²°ê³¼ ===
{st.session_state.analysis_result}

"""
                                
                                if 'generated_titles' in st.session_state:
                                    content += f"""
=== ìƒì„±ëœ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ì œëª©ë“¤ ===
{st.session_state.generated_titles}
"""
                                
                                st.download_button(
                                    label="ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                    data=content,
                                    file_name=filename,
                                    mime="text/plain",
                                    use_container_width=True
                                )
            else:
                st.error("ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì œëª©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error("ë¸”ë¡œê·¸ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    # í‘¸í„°
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666; padding: 2rem;">
        <p><strong>KeiaiLAB ë¸”ë¡œê·¸ ê¸€ìƒì„±ê¸°</strong> | AI ê¸°ë°˜ ë¸”ë¡œê·¸ ì œëª© ë¶„ì„ ë° ìƒì„± ë„êµ¬</p>
        <p>Powered by GPT-4o & Naver Search API</p>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main() 