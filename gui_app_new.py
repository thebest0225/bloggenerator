import streamlit as st
import urllib.request
import urllib.parse
import urllib.error
import json
import re
import time
import io
from openai import OpenAI
import prompts

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="KeiaiLAB ë¸”ë¡œê·¸ ê¸€ìƒì„±ê¸°",
    page_icon="ğŸ“",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        margin-bottom: 2rem;
        text-align: center;
        color: white;
    }
    .result-container {
        background-color: #f8f9fa;
        padding: 1.5rem;
        border-radius: 8px;
        border-left: 4px solid #667eea;
        margin: 1rem 0;
        white-space: pre-wrap;
    }
    .metric-container {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

def load_env_variables():
    """í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
    env_vars = {}
    try:
        with open('.env', 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key.strip()] = value.strip()
    except FileNotFoundError:
        return None, None, None
    
    return (
        env_vars.get('NAVER_CLIENT_ID'),
        env_vars.get('NAVER_CLIENT_SECRET_KEY'),
        env_vars.get('OPENAI_API_KEY')
    )

def search_naver_blog(query, client_id, client_secret, display=50, sort='date'):
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰"""
    enc_text = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/blog.json?query={enc_text}&display={display}&sort={sort}"
    
    request = urllib.request.Request(url)
    request.add_header("X-Naver-Client-Id", client_id)
    request.add_header("X-Naver-Client-Secret", client_secret)
    
    try:
        response = urllib.request.urlopen(request)
        if response.getcode() == 200:
            response_body = response.read()
            return json.loads(response_body.decode('utf-8'))
        else:
            st.error(f"API ì‘ë‹µ ì˜¤ë¥˜: HTTP {response.getcode()}")
            return None
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8')
        st.error(f"ë„¤ì´ë²„ API ì˜¤ë¥˜ ({e.code}): {error_body}")
        st.info("ğŸ’¡ .env íŒŒì¼ì˜ NAVER_CLIENT_SECRET_KEYë¥¼ ë„¤ì´ë²„ ê°œë°œìì„¼í„°ì—ì„œ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None
    except Exception as e:
        st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def clean_html_tags(text):
    """HTML íƒœê·¸ ì œê±°"""
    clean = re.compile('<.*?>')
    return re.sub(clean, '', text)

def extract_blog_data(search_result):
    """ë¸”ë¡œê·¸ ë°ì´í„° ì¶”ì¶œ"""
    if not search_result or 'items' not in search_result:
        return [], []
    
    titles = []
    descriptions = []
    
    for item in search_result['items']:
        title = clean_html_tags(item.get('title', ''))
        description = clean_html_tags(item.get('description', ''))
        
        if title:
            titles.append(title)
            descriptions.append(description)
    
    return titles, descriptions

def analyze_with_gpt(titles, descriptions, query, openai_api_key, analysis_type='comprehensive'):
    """GPTë¡œ ë¸”ë¡œê·¸ ì œëª© ë¶„ì„"""
    try:
        client = OpenAI(api_key=openai_api_key)
        
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = prompts.get_system_prompt(analysis_type)
        user_prompt = prompts.create_analysis_prompt(query, titles, analysis_type)
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=3000,
            temperature=0.7
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        st.error(f"GPT ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def generate_new_titles(analysis_result, query, openai_api_key, num_titles=10):
    """ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ì œëª© ìƒì„±"""
    try:
        client = OpenAI(api_key=openai_api_key)
        
        system_prompt = prompts.get_title_generation_system_prompt()
        user_prompt = prompts.create_title_generation_prompt(query, analysis_result, num_titles)
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            max_tokens=2000,
            temperature=0.8
        )
        
        return response.choices[0].message.content
        
    except Exception as e:
        st.error(f"ì œëª© ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def main():
    # í—¤ë”
    st.markdown("""
    <div class="main-header">
        <h1>ğŸ“ KeiaiLAB ë¸”ë¡œê·¸ ê¸€ìƒì„±ê¸°</h1>
        <p>AI ê¸°ë°˜ ë¸”ë¡œê·¸ ì œëª© ë¶„ì„ ë° ì‹ ê·œ ì œëª© ìƒì„± ë„êµ¬</p>
    </div>
    """, unsafe_allow_html=True)
    
    # í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
    client_id, client_secret, openai_api_key = load_env_variables()
    
    if not all([client_id, client_secret, openai_api_key]):
        st.error("ğŸš¨ .env íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”. API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        st.info("""
        ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ .env íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”:
        ```
        NAVER_CLIENT_ID=your_naver_client_id
        NAVER_CLIENT_SECRET_KEY=your_naver_client_secret
        OPENAI_API_KEY=your_openai_api_key
        ```
        """)
        return
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.markdown("### âš™ï¸ ì„¤ì •")
        
        # ê²€ìƒ‰ ì„¤ì •
        st.markdown("### ğŸ” ê²€ìƒ‰ ì„¤ì •")
        search_count = st.slider("ë¶„ì„í•  ë¸”ë¡œê·¸ ê°œìˆ˜", 10, 100, 50)
        sort_method = st.radio("ì •ë ¬ ë°©ì‹", ["ë‚ ì§œìˆœ (ìµœì‹ ìˆœ)", "ì •í™•ë„ìˆœ"])
        sort_value = 'date' if sort_method == "ë‚ ì§œìˆœ (ìµœì‹ ìˆœ)" else 'sim'
        
        st.markdown("---")
        
        # ë¶„ì„ ì„¤ì •
        st.markdown("### ğŸ§  ë¶„ì„ ì„¤ì •")
        analysis_types = prompts.get_available_analysis_types()
        
        selected_analysis = st.selectbox(
            "ë¶„ì„ ìœ í˜• ì„ íƒ",
            options=list(analysis_types.keys()),
            format_func=lambda x: analysis_types[x]['name'],
            help="ì›í•˜ëŠ” ë¶„ì„ ìœ í˜•ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        st.markdown("---")
        
        # ì œëª© ìƒì„± ì„¤ì •
        st.markdown("### âœ¨ ì œëª© ìƒì„± ì„¤ì •")
        num_titles = st.slider("ìƒì„±í•  ì œëª© ê°œìˆ˜", 5, 30, 10)
    
    # ë©”ì¸ ì˜ì—­
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.markdown("### ğŸ” í‚¤ì›Œë“œ ì…ë ¥")
        query = st.text_input(
            "ë¶„ì„í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ë°˜ë ¤ë™ë¬¼, ìš”ë¦¬, ì—¬í–‰ ë“±",
            help="ë„¤ì´ë²„ ë¸”ë¡œê·¸ì—ì„œ ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
        )
    
    with col2:
        st.markdown("### ğŸš€ ì‹¤í–‰")
        analyze_button = st.button("ë¶„ì„ ì‹œì‘", use_container_width=True, type="primary")
    
    # ë¶„ì„ ì‹¤í–‰
    if analyze_button and query.strip():
        with st.spinner("ğŸ” ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê²€ìƒ‰ ì¤‘..."):
            search_result = search_naver_blog(query, client_id, client_secret, search_count, sort_value)
        
        if search_result:
            titles, descriptions = extract_blog_data(search_result)
            
            if titles:
                # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
                st.markdown("### ğŸ“Š ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("ì´ ê²€ìƒ‰ ê²°ê³¼", f"{search_result.get('total', 0):,}ê°œ")
                with col2:
                    st.metric("ìˆ˜ì§‘ëœ ì œëª©", f"{len(titles)}ê°œ")
                with col3:
                    st.metric("í‰ê·  ì œëª© ê¸¸ì´", f"{sum(len(t) for t in titles)/len(titles):.1f}ì")
                
                # ë¶„ì„ ì‹¤í–‰
                with st.spinner("ğŸ§  AI ë¶„ì„ ì¤‘..."):
                    analysis_result = analyze_with_gpt(titles, descriptions, query, openai_api_key, selected_analysis)
                
                if analysis_result:
                    # íƒ­ìœ¼ë¡œ ê²°ê³¼ ë¶„ë¦¬
                    tab1, tab2 = st.tabs(["ğŸ“ ìˆ˜ì§‘ëœ ì œëª© ëª©ë¡", "ğŸ“‹ AI ë¶„ì„ ê²°ê³¼"])
                    
                    with tab1:
                        st.markdown("#### ğŸ” ê²€ìƒ‰ëœ ë¸”ë¡œê·¸ ì œëª©ë“¤")
                        for i, title in enumerate(titles, 1):
                            st.write(f"**{i:2d}.** {title}")
                    
                    with tab2:
                        st.markdown("#### ğŸ§  AI ë¶„ì„ ë³´ê³ ì„œ")
                        st.markdown(f'<div class="result-container">{analysis_result}</div>', unsafe_allow_html=True)
                    
                    # ì œëª© ìƒì„± ë° ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                    st.markdown("### âœ¨ ì¶”ê°€ ê¸°ëŠ¥")
                    
                    col1, col2 = st.columns([1, 1])
                    with col1:
                        if st.button("ğŸ¯ ìƒˆë¡œìš´ ì œëª© ìƒì„±", use_container_width=True):
                            with st.spinner(f"âœ¨ {num_titles}ê°œì˜ ìƒˆë¡œìš´ ì œëª© ìƒì„± ì¤‘..."):
                                generated_titles = generate_new_titles(analysis_result, query, openai_api_key, num_titles)
                            
                            if generated_titles:
                                st.markdown("### ğŸ‰ ìƒì„±ëœ ìƒˆë¡œìš´ ì œëª©ë“¤")
                                st.markdown(f'<div class="result-container">{generated_titles}</div>', unsafe_allow_html=True)
                    
                    with col2:
                        if st.button("ğŸ’¾ ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", use_container_width=True):
                            # ê²°ê³¼ íŒŒì¼ ìƒì„±
                            timestamp = time.strftime("%Y%m%d_%H%M%S")
                            filename = f"blog_analysis_{query}_{timestamp}.txt"
                            
                            content = f"""=== KeiaiLAB ë¸”ë¡œê·¸ ì œëª© ë¶„ì„ ë° ìƒì„± ê²°ê³¼ ===
ê²€ìƒ‰ í‚¤ì›Œë“œ: {query}
ë¶„ì„ ì¼ì‹œ: {time.strftime('%Y-%m-%d %H:%M:%S')}
ë¶„ì„ ìœ í˜•: {analysis_types[selected_analysis]['name']}

=== ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ ===
ì´ ê²€ìƒ‰ ê²°ê³¼: {search_result.get('total', 0):,}ê°œ
ìˆ˜ì§‘ëœ ì œëª©: {len(titles)}ê°œ
í‰ê·  ì œëª© ê¸¸ì´: {sum(len(t) for t in titles)/len(titles):.1f}ì

=== ìˆ˜ì§‘ëœ ì œëª© ëª©ë¡ ===
""" + "\n".join([f"{i:2d}. {title}" for i, title in enumerate(titles, 1)]) + f"""

=== AI ë¶„ì„ ê²°ê³¼ ===
{analysis_result}
"""
                            
                            # ë‹¤ìš´ë¡œë“œ ì œê³µ
                            st.download_button(
                                label="ğŸ“¥ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
                                data=content.encode('utf-8'),
                                file_name=filename,
                                mime='text/plain',
                                use_container_width=True
                            )
                else:
                    st.error("AI ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning("ìˆ˜ì§‘ëœ ë¸”ë¡œê·¸ ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error("ë¸”ë¡œê·¸ ê²€ìƒ‰ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    
    elif analyze_button and not query.strip():
        st.warning("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”!")

if __name__ == "__main__":
    main() 